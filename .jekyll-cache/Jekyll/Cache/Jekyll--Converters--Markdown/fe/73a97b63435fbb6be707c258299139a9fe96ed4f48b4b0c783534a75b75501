I"5<h1 id="deep-learning-for-process-control">Deep Learning for Process Control</h1>

<p>Traditional controllers used in the process industries, such as PID loops or MPC, require constant attention and upkeep for its entire lifecycle including modeling, design, tuning and maintenance. These controllers are typically designed for a narrow operating range by assuming linear process behavior, and are not resilient to changes in plant equipment or operating conditions. In complex industrial systems, there often exists a trade-off between high performance controllers and the development of complex models that are computationally intensive and difficult to interpret or maintain.</p>

<div class="columns">
  <div class="column is-one-quarter is-hidden-mobile"></div>
  <div class="column">
    <figure class="image">
      <img src="/assets/img/pexels-magda-ehlers-2569842.jpg" alt="Photo of industrial plant and piping" title="Photo of industrial plant and piping. Royalty-free image from Pexel" />
    </figure>
  </div>
  <div class="column is-one-quarter is-hidden-mobile"></div>
</div>

<p>Inspired by the recent successes of deep learning in computer vision and natural language processing, our group is exploring deep reinforcement learning (DRL) as a model-free and maintenance-free framework for process control in industrial settings. Recent work that weâ€™ve published shows promising results for DRL in terms of setpoint tracking performance and adaptability, but there are still many fundamental questions left to explore, including sample efficiency (big data is not always good data), stability guarantees, interpretability and computational challenges.</p>

<p>Ultimately, we are interested in the development of smart plants and advanced controllers that can provide a high level of safety and reliability for the industry.</p>

<div class="columns">
  <div class="column">
    <figure class="image">
      <img src="/assets/img/deeprl.png" alt="Reinforcement Learning based Design of Linear Fixed Structure Controllers" title="Reinforcement Learning based Design of Linear Fixed Structure Controllers" />
    </figure>
    <figcaption><b>Reinforcement Learning based Design of Linear Fixed Structure Controllers - Lawrence et al. (2020): </b>A standard closed-loop structure is shown inside the dashed box. Arrows passing the dashed line indicate the passing of some time-horizon [0, T]. Outside the dashed box, we store cumulative rewards based on slightly perturbed policies, which are used to update the policy with a finite-difference scheme described in section 4.2 in the manuscript.</figcaption>
  </div>
  <div class="column">
    <figure class="image">
      <img src="/assets/img/deeprl_pid.png" alt="Optimal PID and Antiwindup Control Design as a Reinforcement Learning Problem" title="Optimal PID and Antiwindup Control Design as a Reinforcement Learning Problem" />
    </figure>
    <figcaption><b>Optimal PID and Antiwindup Control Design as a Reinforcement Learning Problem - Lawrence et al. (2020): </b>The actor (PID controller) on the left is simply linear combination of the state and the PID &amp; antiwindup parameters followed by a nonlinear saturation function. The critic on the right is a deep neural network approximation of the Q-function whose inputs are the state-action pair generated by the actor.</figcaption>
  </div>
</div>

<div class="columns">
  <div class="column">
    <div class="video-wrapper">
      <iframe src="https://player.vimeo.com/video/455075386" width="640" height="361" frameborder="0" allow="autoplay; fullscreen" allowfullscreen=""></iframe>
    </div>    
  </div>
  <div class="column">
    <div class="video-wrapper">
      <iframe src="https://player.vimeo.com/video/455075443" width="640" height="361" frameborder="0" allow="autoplay; fullscreen" allowfullscreen=""></iframe>
    </div>
  </div>
</div>

<h2 id="selected-publications">Selected Publications</h2>

<p>See below for a selection of our papers related to deep (reinforcement) learning.</p>

<ol class="list is-hoverable">


<li class="list-item" style="display: list-item">
  
    <i>Conference Proceedings</i>
  
     
  <br />

  <b class="large">Almost Surely Stable Deep Dynamics</b><br />
  Nathan P. Lawrence, Philip D. Loewen, Michael G. Forbes, Johan U. Backstrom and R. Bhushan Gopaluni<br />
  <i>
  
  In Proceedings of Advances in Neural Information Processing Systems 33 (NeurIPS 2020, To Appear).
  
  </i>
  
  2020

  
  <a target="_blank" href="/assets/preprints/2020C6_Lawrence_NeurIPS.pdf"><span class="tag is-info">[PDF]</span></a>
   

  

       

  

  

     
      
</li>











<li class="list-item" style="display: list-item">
  
    <i>Conference Proceedings</i>
  
     
  <br />

  <b class="large">Deep Neural Network Approximation of Nonlinear Model Predictive Control</b><br />
  Yankai Cao, R. Bhushan Gopaluni<br />
  <i>
  
  In proceedings of IFAC World Congress (To Appear).
  
  </i>
  
  2020

  
  <a target="_blank" href="/assets/preprints/IFAC20_3818_FI.pdf"><span class="tag is-info">[PDF]</span></a>
   

  
  <a target="_blank" href="/assets/preprints/2020IFAC_Yankai_Slides.pdf"><span class="tag is-warning">[Slides]</span></a>
  

       

  

  

  
  <a target="_blank" href="https://vimeo.com/456390157"><span class="tag is-primary">[Video]</span></a>
     
      
</li>



<li class="list-item" style="display: list-item">
  
    <i>Conference Proceedings</i>
  
     
  <br />

  <b class="large">Optimal PID and Antiwindup Control Design as a Reinforcement Learning Problem</b><br />
  Nathan P. Lawrence, Gregory E. Stewart, Philip D. Loewen, Michael G. Forbes, Johan U. Backstrom, R. Bhushan Gopaluni<br />
  <i>
  
  In proceedings of IFAC World Congress (To Appear).
  
  </i>
  
  2020

  
  <a target="_blank" href="/assets/preprints/IFAC_PID_RL_2020-7.pdf"><span class="tag is-info">[PDF]</span></a>
   

  

       

  

  

  
  <a target="_blank" href="https://vimeo.com/455075386"><span class="tag is-primary">[Video]</span></a>
     
      
</li>



<li class="list-item" style="display: list-item">
  
    <i>Conference Proceedings</i>
  
     
  <br />

  <b class="large">Reinforcement Learning based Design of Linear Fixed Structure Controllers</b><br />
  Nathan P. Lawrence, Gregory E. Stewart, Philip D. Loewen, Michael G. Forbes, Johan U. Backstrom, R. Bhushan Gopaluni<br />
  <i>
  
  In proceedings of IFAC World Congress (To Appear).
  
  </i>
  
  2020

  
  <a target="_blank" href="/assets/preprints/IFAC_PID_RL_2020-8.pdf"><span class="tag is-info">[PDF]</span></a>
   

  

       

  

  

  
  <a target="_blank" href="https://vimeo.com/455075443"><span class="tag is-primary">[Video]</span></a>
     
      
</li>













<li class="list-item" style="display: list-item">
  
    <i>Journal Paper</i>
  
  
  <span class="tag is-info is-light">Top 10% Most Downloaded</span>
     
  <br />

  <b class="large">Towards Self-Driving Processes: A Deep Reinforcement Learning Approach to Control</b><br />
  Steven P. Spielberg, Aditya Tulsyan, Nathan P. Lawrence, Philip D. Loewen, R. Bhushan Gopaluni<br />
  <i>
  
  <a target="_blank" href="https://aiche.onlinelibrary.wiley.com/doi/abs/10.1002/aic.16689">
    AIChE Journal.
  </a>
  
  </i>
  
  2019

  
  <a target="_blank" href="/assets/preprints/2019J9_Spielberg_AIChE.pdf"><span class="tag is-info">[PDF]</span></a>
   

  

       

  

  

     
      
</li>


















































































































































































































































































</ol>

:ET